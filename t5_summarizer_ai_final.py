# -*- coding: utf-8 -*-
"""T5_Summarizer_AI_FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ejyqiOmma29-OKVWcWq339s6U_AGOwzN
"""

# ignore warnings

import warnings
warnings.filterwarnings("ignore")

"""Installing Dependencies"""

! pip3 install torch torchvision
! pip install datasets
! pip install rouge

"""Load dataset"""

from datasets import load_dataset
multi_news = load_dataset("multi_news", split="test")

"""View Data"""

data = multi_news.to_pandas()
data.to_csv('dataframe.csv', index=False)

multi_news_test_train = multi_news[:5522]
multi_news_validation = multi_news[-100:]

from datasets import Dataset
multi_news_test_train = Dataset.from_dict(multi_news_test_train)

"""Train test split (80:20 ratio respectively)"""

multi_news_test_train = multi_news_test_train.train_test_split(test_size=0.2)

"""Tokenizing Training and testing sets"""

! pip install transformers==4.28.0

from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("t5-small")

prefix = "summarize: "

def preprocess_function(examples):
    inputs = [prefix + doc for doc in examples["document"]]
    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)
    labels = tokenizer(text=examples["summary"], max_length=128, truncation=True)
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_multi_news_test_train = multi_news_test_train.map(preprocess_function, batched=True)

"""Model Loading"""

from transformers import DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer

data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model='t5-small')
model = AutoModelForSeq2SeqLM.from_pretrained("t5-small")

"""Defining Hyperparameters"""

training_args = Seq2SeqTrainingArguments(
output_dir="./results",
evaluation_strategy="epoch",
learning_rate=2e-5,
per_device_train_batch_size=10,
per_device_eval_batch_size=10,
weight_decay=0.01,
save_total_limit=3,
num_train_epochs=25,
fp16=False,
)

"""Initializing Trainer"""

trainer = Seq2SeqTrainer(
model=model,
args=training_args,
train_dataset=tokenized_multi_news_test_train["train"],
eval_dataset=tokenized_multi_news_test_train["test"],
tokenizer=tokenizer,
data_collator=data_collator,
)

"""Train the Text Summarization Model"""

trainer.train()

from google.colab import files
files.download('/content/model2.pth')

from google.colab import drive

drive.mount('/content/drive')

import shutil

source_path = '/content/dataframe_final_results_25.csv'
destination_path = '/content/drive/MyDrive/final_data'

shutil.copy(source_path, destination_path)

"""Evaluate model on a single document"""

document = " Tesla (TSLA.O) shares jumped 6% on Friday on expectations that its electric-vehicle charging system would become an industry standard after General Motors (GM.N) joined cross-town rival Ford (F.N) in agreeing to use the Tesla Supercharger network. The Elon Musk-led automaker was on course for its eleventh straight session of gains, which would mark its longest winning streak in 2-1/2 years. Tesla was also among the most traded stock across U.S. exchanges.Already the world's most valuable automaker, Tesla was set to increase its market capitalization by more than $30 billion to about $780 billion. Shares of General Motors, whose market capitalization is much lower at $49.8 billion but sells millions more vehicles annually, rose nearly 5%. The rare partnership among three of the biggest U.S. automakers ensures that nearly 70% of the country's EV market will have access to Tesla's North American Charging Standard (NACS).That will put pressure on other companies to upgrade their networks to work with Tesla's at a time when many lag in customer service and lack the funds to make such a commitment. Shares of charging companies such as ChargePoint Holdings Inc (CHPT.N), EVgo Inc (EVGO.O) and Blink Charging Co (BLNK.O) were down between 3.0% and 10%. It's a huge boost for Tesla's charging business, said Consumer Reports senior policy analyst Chris Harto. They are like to cement themselves as the number one charging network in the country. It definitely could become a big profit center for them going forward. Wedbush Securities estimated Ford and GM combined could add $3 billion to services EV charging revenue for Tesla over the next few years. The brokerage also raised its price target on Tesla shares to $300, which is nearly 30% above their last close.The stock has a forward 12-month price-to-earnings ratio of 60.46, among the highest in the S&P 500 index (.SPX) and above GM's 5.29 and 7.94 for Ford. Tesla's NACS is more widespread and reliable than CCS, or the combined charging system, which the U.S. government has tried to support by setting aside $7.5 billion in federal funds. Many complain that the CCS charging infrastructure is inefficient or sometimes inoperable, leading prospective buyers to fear becoming stranded on the road with nowhere to charge. Greater usage of Tesla Superchargers could, however, create its own problems for the Musk-led company, said Michael Austin, senior research analyst at Guidehouse. There is a risk for Tesla in terms of either making the stations too busy and disappointing Tesla owners or removing that competitive advantage of having exclusive access to the best network, Austin said."

import torch
model = AutoModelForSeq2SeqLM.from_pretrained("t5-small")
model.load_state_dict(torch.load('/content/drive/MyDrive/AI MINI PROJECT/model_25_final/pytorch_model.bin'))
model.eval()

def predict_summary(document):
  device = model.device
  tokenized = tokenizer([document], truncation =True, padding ='longest',return_tensors='pt')
  tokenized = {k: v.to(device) for k, v in tokenized.items()}
  tokenized_result = model.generate(**tokenized, max_length=128)
  tokenized_result = tokenized_result.to('cpu')
  predicted_summary = tokenizer.decode(tokenized_result[0])
  return predicted_summary

predicted_summary = predict_summary(document)
predicted_summary

"""Evaluate using Rouge Scores

ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a suite of metrics for evaluating the quality of text summaries. It compares a set of reference summaries with a set of generated summaries, and computes a score based on the overlap between the two.
"""

from rouge import Rouge

def get_rouge_scores(actual_summary, predicted_summary):
    rouge = Rouge()
    scores = rouge.get_scores(predicted_summary, actual_summary)
    return [scores[0]['rouge-1']['f'], scores[0]['rouge-2']['f'], scores[0]['rouge-l']['f']]

# import validation dataset

import pandas as pd
val_data = multi_news_validation
val_data = pd.DataFrame(val_data)
val_data
val_data.to_csv('dataframe_validation.csv', index=False)

# rouge score of validation data

from tqdm import tqdm

rouge1_scores = []
rouge2_scores = []
rougel_scores = []

pred_summary_list = []

for i in tqdm(range(len(val_data))):
    doc = val_data.loc[i]['document']
    pred_summary = predict_summary(doc)
    human_summary = val_data.loc[i]['summary']

    # Remove extra tokens from generated summary
    pred_summary = pred_summary.replace("<extra_id_0>", "").replace("<extra_id_1>", "").replace("<extra_id_2>", "").replace("<extra_id_3>", "")
    pred_summary = pred_summary.replace("<extra_id_4>", "").replace("<extra_id_5>", "").replace("<extra_id_6>", "")

    # Refine the summary further if needed
    refined_summary = pred_summary.strip()

    score = get_rouge_scores(human_summary, refined_summary)

    rouge1_scores.append(score[0])
    rouge2_scores.append(score[1])
    rougel_scores.append(score[2])

    pred_summary_list.append(refined_summary)

val_data["pred_summary"] = pred_summary_list
val_data['rouge1'] = rouge1_scores
val_data['rouge2'] = rouge2_scores
val_data['rougel'] = rougel_scores

val_data

from google.colab import drive
drive.mount('/content/drive')

val_data.to_csv('dataframe_final_results_25.csv', index=False)

# average rouge 1
val_data['rouge1'].mean()

# average rouge 2
val_data['rouge2'].mean()

# average rouge l
val_data['rougel'].mean()

import matplotlib.pyplot as plt
avg_rouge1 = val_data['rouge1'].mean()
avg_rouge2 = val_data['rouge2'].mean()
avg_rougel = val_data['rougel'].mean()

# Create a list of average scores
avg_scores = [avg_rouge1, avg_rouge2, avg_rougel]

# Create a list of ROUGE names
rouge_names = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']

# Create a bar plot
plt.bar(rouge_names, avg_scores)
plt.xlabel('ROUGE')
plt.ylabel('Score')
plt.title('Average ROUGE Scores')
plt.show()